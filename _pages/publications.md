---
layout: archive
title: "Publications"
permalink: /publications/
author_profile: true
---

The * sign stands for co-first authors (equal contribution). 
You can also find the publications on my [Google Scholar page](https://scholar.google.com/citations?user=loi95BwAAAAJ). 

<!-- ## Preprints -->

<!-- --- -->

## Journal Articles

<div class="publication" style="display: flex; align-items: stretch; margin-bottom: 30px;">
  <img src="/images/publications/grad_nav_pp.png" alt="GRaD-Nav++" style="width: 240px; height: 150px; object-fit: fill; margin-right: 20px; border-radius: 8px;">
  <div>
    <strong> [RA-L 2025] GRaD-Nav++: Vision-Language Model Enabled Visual Drone Navigation with Gaussian Radiance Fields and Differentiable Dynamics</strong><br>
    Q. Chen*, <strong>N. Gao*</strong>, S. Huang, J. Low, T. Chen, J. Sun, M. Schwager<br>
    <a href="https://www.arxiv.org/abs/2506.14009" target="_blank">arXiv</a> |
    <a href="https://qianzhong-chen.github.io/gradnavpp.github.io/" target="_blank">website</a> |
    <a href="https://github.com/Qianzhong-Chen/grad_nav" target="_blank">code</a><br>
    <strong>Summary:</strong> GRaD-Nav++ is a lightweight, fully onboard Vision-Language-Action framework that enables drones to follow natural language commands in real time using DiffRL training in a 3DGS simulator, achieving strong generalization across tasks and environments both in simulation and on real hardware.
  </div>
</div>

<div class="publication" style="display: flex; align-items: stretch; margin-bottom: 30px;">
  <img src="/images/publications/trackdlo.png" alt="TrackDLO" style="width: 240px; height: 150px; object-fit: fill; margin-right: 20px; border-radius: 8px;">
  <div>
    <strong>[RA-L 2023] TrackDLO: Tracking Deformable Linear Objects Under Occlusion With Motion Coherence</strong><br>
    J. Xiang, H. Dinkel, H. Zhao, <strong>N. Gao</strong>, B. Coltin, T. Smith, T. Bretl<br>
    <em>IEEE Robotics and Automation Letters</em>, vol. 8, no. 10, pp. 6179-6186, Oct. 2023<br>
    <a href="https://ieeexplore.ieee.org/document/10214157" target="_blank">paper</a> |
    <a href="https://github.com/RMDLO/trackdlo" target="_blank">code</a><br>
    <strong>Summary:</strong> TrackDLO presents a real-time method for tracking deformable linear objects under severe occlusion by leveraging motion coherence, geodesic topology, and a physics-inspired non-Gaussian kernel, achieving robust and accurate tracking without markers or simulations.
  </div>
</div>

---

## Conferences

<div class="publication" style="display: flex; align-items: stretch; margin-bottom: 30px;">
  <img src="/images/publications/gradnav.png" alt="GRaD-Nav" style="width: 240px; height: 150px; object-fit: fill; margin-right: 20px; border-radius: 8px;">
  <div>
    <strong>[IROS 2025] GRaD-Nav: Efficiently learning visual drone navigation with Gaussian radiance fields and differentiable dynamics</strong><br>
    Q. Chen, J. Sun, <strong>N. Gao</strong>, J. Low, T. Chen, M. Schwager<br>
    <a href="https://arxiv.org/abs/2503.03984" target="_blank">arXiv</a> |
    <a href="https://qianzhong-chen.github.io/gradnav.github.io/" target="_blank">website</a> |
    <a href="https://github.com/Qianzhong-Chen/grad_nav" target="_blank">code</a><br>
    <strong>Summary:</strong> We propose a vision-based drone navigation framework that leverages differentiable dynamics and Gaussian radiance fields for sample-efficient learning and robust generalization.
  </div>
</div>
